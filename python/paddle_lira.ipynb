{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d59641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:23.732399Z",
     "start_time": "2021-08-16T18:32:22.817905Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib\n",
    "import PIL\n",
    "import six\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dabe59ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:23.787586Z",
     "start_time": "2021-08-16T18:32:23.734515Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(filename, gen_data):\n",
    "    pad_dim = 1\n",
    "    paded = pad_dim + img_dim\n",
    "    gen_data = gen_data.reshape(gen_data.shape[0], img_dim, img_dim)\n",
    "    n = int(math.ceil(math.sqrt(gen_data.shape[0])))\n",
    "    gen_data = (np.pad(\n",
    "        gen_data, [[0, n * n - gen_data.shape[0]], [pad_dim, 0], [pad_dim, 0]],\n",
    "        'constant').reshape((n, n, paded, paded)).transpose((0, 2, 1, 3))\n",
    "                .reshape((n * paded, n * paded)))\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    plt.imsave(filename, gen_data, cmap='Greys_r', vmin=-1, vmax=1)\n",
    "    return fig\n",
    "\n",
    "gf_dim = 64 # the number of basic channels of the generator's feature map. The number of all the channels of feature maps in the generator is a multiple of the number of basic channels\n",
    "df_dim = 64 # the number of basic channels of the discriminator's feature map. The number of all the channels of feature maps in the discriminator is a multiple of the number of basic channels\n",
    "gfc_dim = 1024 * 2 # the dimension of full connection layer of generator\n",
    "dfc_dim = 1024 # the dimension of full connection layer of discriminator\n",
    "img_dim = 28  # size of the input picture\n",
    "\n",
    "NOISE_SIZE = 100  # dimension of input noise\n",
    "LEARNING_RATE = 2e-4 # learning rate of training\n",
    "\n",
    "epoch = 20         # epoch number of training\n",
    "output = \"./output_dcgan\"   # storage path of model and test results\n",
    "use_cudnn = False  # use cuDNN or not\n",
    "use_gpu=True       # use GPU or not\n",
    "\n",
    "def bn(x, name=None, act='relu'):\n",
    "    return fluid.layers.batch_norm(\n",
    "        x,\n",
    "        param_attr=name + '1',\n",
    "        bias_attr=name + '2',\n",
    "        moving_mean_name=name + '3',\n",
    "        moving_variance_name=name + '4',\n",
    "        name=name,\n",
    "        act=act)\n",
    "\n",
    "def conv(x, num_filters, name=None, act=None):\n",
    "    return fluid.nets.simple_img_conv_pool(\n",
    "        input=x,\n",
    "        filter_size=5,\n",
    "        num_filters=num_filters,\n",
    "        pool_size=2,\n",
    "        pool_stride=2,\n",
    "        param_attr=name + 'w',\n",
    "        bias_attr=name + 'b',\n",
    "        use_cudnn=use_cudnn,\n",
    "        act=act)\n",
    "\n",
    "def fc(x, num_filters, name=None, act=None):\n",
    "    return fluid.layers.fc(input=x,\n",
    "                           size=num_filters,\n",
    "                           act=act,\n",
    "                           param_attr=name + 'w',\n",
    "                           bias_attr=name + 'b')\n",
    "def deconv(x,\n",
    "           num_filters,\n",
    "           name=None,\n",
    "           filter_size=5,\n",
    "           stride=2,\n",
    "           dilation=1,\n",
    "           padding=2,\n",
    "           output_size=None,\n",
    "           act=None):\n",
    "    return fluid.layers.conv2d_transpose(\n",
    "        input=x,\n",
    "        param_attr=name + 'w',\n",
    "        bias_attr=name + 'b',\n",
    "        num_filters=num_filters,\n",
    "        output_size=output_size,\n",
    "        filter_size=filter_size,\n",
    "        stride=stride,\n",
    "        dilation=dilation,\n",
    "        padding=padding,\n",
    "        use_cudnn=use_cudnn,\n",
    "        act=act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189b1523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:23.942075Z",
     "start_time": "2021-08-16T18:32:23.788969Z"
    }
   },
   "outputs": [],
   "source": [
    "def D(x, num_classes):\n",
    "    x = fluid.layers.reshape(x=x, shape=[-1, 1, 28, 28])\n",
    "    x = conv(x, df_dim, act='leaky_relu',name='conv1')\n",
    "    x = bn(conv(x, df_dim * 2,name='conv2'), act='leaky_relu',name='bn1')\n",
    "    x = bn(fc(x, dfc_dim,name='fc1'), act='leaky_relu',name='bn2')\n",
    "    x = fc(x, num_classes, act='sigmoid',name='fc2')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5caa6ed6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:24.014169Z",
     "start_time": "2021-08-16T18:32:23.944297Z"
    }
   },
   "outputs": [],
   "source": [
    "def G(x):\n",
    "    x = bn(fc(x, gfc_dim,name='fc3'),name='bn3')\n",
    "    x = bn(fc(x, gf_dim * 2 * img_dim // 4 * img_dim // 4,name='fc4'),name='bn4')\n",
    "    x = fluid.layers.reshape(x, [-1, gf_dim * 2, img_dim // 4, img_dim // 4])\n",
    "    x = deconv(x, gf_dim * 2, act='relu', output_size=[14, 14],name='deconv1')\n",
    "    x = deconv(x, num_filters=1, filter_size=5, padding=2, act='tanh', output_size=[28, 28],name='deconv2')\n",
    "    x = fluid.layers.reshape(x, shape=[-1, 28 * 28])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c593a6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:24.080402Z",
     "start_time": "2021-08-16T18:32:24.016239Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss(x, label):\n",
    "    return fluid.layers.mean(\n",
    "        fluid.layers.sigmoid_cross_entropy_with_logits(x=x, label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "758e176f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:24.205343Z",
     "start_time": "2021-08-16T18:32:24.085487Z"
    }
   },
   "outputs": [],
   "source": [
    "paddle.enable_static()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7036e5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:24.326692Z",
     "start_time": "2021-08-16T18:32:24.207565Z"
    }
   },
   "outputs": [],
   "source": [
    "d_program = fluid.Program()\n",
    "dg_program = fluid.Program()\n",
    "\n",
    "# Define the program to distinguish the real picture\n",
    "with fluid.program_guard(d_program):\n",
    "    # size of the input picture is28*28=784\n",
    "    img = fluid.data(name='img', shape=[None, 784], dtype='float32')\n",
    "    # label shape=1\n",
    "    label = fluid.data(name='label', shape=[None, 1], dtype='float32')\n",
    "    d_logit = D(img, 1)\n",
    "    d_loss = loss(d_logit, label)\n",
    "\n",
    "# Define the program to distinguish the generated pictures\n",
    "with fluid.program_guard(dg_program):\n",
    "    noise = fluid.data(\n",
    "        name='noise', shape=[None, NOISE_SIZE], dtype='float32')\n",
    "    # Noise data as input to generate image\n",
    "    g_img = G(x=noise)\n",
    "\n",
    "    g_program = dg_program.clone()\n",
    "    g_program_test = dg_program.clone(for_test=True)\n",
    "\n",
    "    # Judge the probability that the generated image is a real sample\n",
    "    dg_logit = D(g_img, 1)\n",
    "\n",
    "    # Calculate the loss of the generated image as the real sample\n",
    "    noise_shape = fluid.layers.shape(noise)\n",
    "    dg_loss = loss(\n",
    "        dg_logit,\n",
    "        fluid.layers.fill_constant(\n",
    "            dtype='float32', shape=[noise_shape[0], 1], value=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b46420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:24.421751Z",
     "start_time": "2021-08-16T18:32:24.328554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{Beta1PowOut=['bn31_beta1_pow_acc_0'], Beta2PowOut=['bn31_beta2_pow_acc_0'], Moment1Out=['bn31_moment1_0'], Moment2Out=['bn31_moment2_0'], ParamOut=['bn31']} = adam(inputs={Beta1Pow=['bn31_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['bn31_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['bn31@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['bn31_moment1_0'], Moment2=['bn31_moment2_0'], Param=['bn31']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_12/, op_role = 2, op_role_var = ['bn31', 'bn31@GRAD']),\n",
       "  {Beta1PowOut=['bn32_beta1_pow_acc_0'], Beta2PowOut=['bn32_beta2_pow_acc_0'], Moment1Out=['bn32_moment1_0'], Moment2Out=['bn32_moment2_0'], ParamOut=['bn32']} = adam(inputs={Beta1Pow=['bn32_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['bn32_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['bn32@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['bn32_moment1_0'], Moment2=['bn32_moment2_0'], Param=['bn32']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_13/, op_role = 2, op_role_var = ['bn32', 'bn32@GRAD']),\n",
       "  {Beta1PowOut=['bn41_beta1_pow_acc_0'], Beta2PowOut=['bn41_beta2_pow_acc_0'], Moment1Out=['bn41_moment1_0'], Moment2Out=['bn41_moment2_0'], ParamOut=['bn41']} = adam(inputs={Beta1Pow=['bn41_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['bn41_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['bn41@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['bn41_moment1_0'], Moment2=['bn41_moment2_0'], Param=['bn41']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_14/, op_role = 2, op_role_var = ['bn41', 'bn41@GRAD']),\n",
       "  {Beta1PowOut=['bn42_beta1_pow_acc_0'], Beta2PowOut=['bn42_beta2_pow_acc_0'], Moment1Out=['bn42_moment1_0'], Moment2Out=['bn42_moment2_0'], ParamOut=['bn42']} = adam(inputs={Beta1Pow=['bn42_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['bn42_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['bn42@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['bn42_moment1_0'], Moment2=['bn42_moment2_0'], Param=['bn42']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_15/, op_role = 2, op_role_var = ['bn42', 'bn42@GRAD']),\n",
       "  {Beta1PowOut=['deconv1b_beta1_pow_acc_0'], Beta2PowOut=['deconv1b_beta2_pow_acc_0'], Moment1Out=['deconv1b_moment1_0'], Moment2Out=['deconv1b_moment2_0'], ParamOut=['deconv1b']} = adam(inputs={Beta1Pow=['deconv1b_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['deconv1b_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['deconv1b@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['deconv1b_moment1_0'], Moment2=['deconv1b_moment2_0'], Param=['deconv1b']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_16/, op_role = 2, op_role_var = ['deconv1b', 'deconv1b@GRAD']),\n",
       "  {Beta1PowOut=['deconv1w_beta1_pow_acc_0'], Beta2PowOut=['deconv1w_beta2_pow_acc_0'], Moment1Out=['deconv1w_moment1_0'], Moment2Out=['deconv1w_moment2_0'], ParamOut=['deconv1w']} = adam(inputs={Beta1Pow=['deconv1w_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['deconv1w_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['deconv1w@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['deconv1w_moment1_0'], Moment2=['deconv1w_moment2_0'], Param=['deconv1w']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_17/, op_role = 2, op_role_var = ['deconv1w', 'deconv1w@GRAD']),\n",
       "  {Beta1PowOut=['deconv2b_beta1_pow_acc_0'], Beta2PowOut=['deconv2b_beta2_pow_acc_0'], Moment1Out=['deconv2b_moment1_0'], Moment2Out=['deconv2b_moment2_0'], ParamOut=['deconv2b']} = adam(inputs={Beta1Pow=['deconv2b_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['deconv2b_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['deconv2b@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['deconv2b_moment1_0'], Moment2=['deconv2b_moment2_0'], Param=['deconv2b']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_18/, op_role = 2, op_role_var = ['deconv2b', 'deconv2b@GRAD']),\n",
       "  {Beta1PowOut=['deconv2w_beta1_pow_acc_0'], Beta2PowOut=['deconv2w_beta2_pow_acc_0'], Moment1Out=['deconv2w_moment1_0'], Moment2Out=['deconv2w_moment2_0'], ParamOut=['deconv2w']} = adam(inputs={Beta1Pow=['deconv2w_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['deconv2w_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['deconv2w@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['deconv2w_moment1_0'], Moment2=['deconv2w_moment2_0'], Param=['deconv2w']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_19/, op_role = 2, op_role_var = ['deconv2w', 'deconv2w@GRAD']),\n",
       "  {Beta1PowOut=['fc3b_beta1_pow_acc_0'], Beta2PowOut=['fc3b_beta2_pow_acc_0'], Moment1Out=['fc3b_moment1_0'], Moment2Out=['fc3b_moment2_0'], ParamOut=['fc3b']} = adam(inputs={Beta1Pow=['fc3b_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['fc3b_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['fc3b@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['fc3b_moment1_0'], Moment2=['fc3b_moment2_0'], Param=['fc3b']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_20/, op_role = 2, op_role_var = ['fc3b', 'fc3b@GRAD']),\n",
       "  {Beta1PowOut=['fc3w_beta1_pow_acc_0'], Beta2PowOut=['fc3w_beta2_pow_acc_0'], Moment1Out=['fc3w_moment1_0'], Moment2Out=['fc3w_moment2_0'], ParamOut=['fc3w']} = adam(inputs={Beta1Pow=['fc3w_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['fc3w_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['fc3w@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['fc3w_moment1_0'], Moment2=['fc3w_moment2_0'], Param=['fc3w']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_21/, op_role = 2, op_role_var = ['fc3w', 'fc3w@GRAD']),\n",
       "  {Beta1PowOut=['fc4b_beta1_pow_acc_0'], Beta2PowOut=['fc4b_beta2_pow_acc_0'], Moment1Out=['fc4b_moment1_0'], Moment2Out=['fc4b_moment2_0'], ParamOut=['fc4b']} = adam(inputs={Beta1Pow=['fc4b_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['fc4b_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['fc4b@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['fc4b_moment1_0'], Moment2=['fc4b_moment2_0'], Param=['fc4b']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_22/, op_role = 2, op_role_var = ['fc4b', 'fc4b@GRAD']),\n",
       "  {Beta1PowOut=['fc4w_beta1_pow_acc_0'], Beta2PowOut=['fc4w_beta2_pow_acc_0'], Moment1Out=['fc4w_moment1_0'], Moment2Out=['fc4w_moment2_0'], ParamOut=['fc4w']} = adam(inputs={Beta1Pow=['fc4w_beta1_pow_acc_0'], Beta1Tensor=[], Beta2Pow=['fc4w_beta2_pow_acc_0'], Beta2Tensor=[], Grad=['fc4w@GRAD'], LearningRate=['learning_rate_1'], MasterParam=[], Moment1=['fc4w_moment1_0'], Moment2=['fc4w_moment2_0'], Param=['fc4w']}, beta1 = 0.8999999761581421, beta2 = 0.9990000128746033, epsilon = 9.99999993922529e-09, lazy_mode = False, min_row_size_to_use_multithread = 1000, multi_precision = False, op_device = , op_namescope = /optimizer_23/, op_role = 2, op_role_var = ['fc4w', 'fc4w@GRAD'])],\n",
       " [(persist trainable param bn42 : LOD_TENSOR.shape(6272,).dtype(float32).stop_gradient(False),\n",
       "   var bn42@GRAD : LOD_TENSOR.shape(6272,).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param bn41 : LOD_TENSOR.shape(6272,).dtype(float32).stop_gradient(False),\n",
       "   var bn41@GRAD : LOD_TENSOR.shape(6272,).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param fc4b : LOD_TENSOR.shape(6272,).dtype(float32).stop_gradient(False),\n",
       "   var fc4b@GRAD : LOD_TENSOR.shape(6272,).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param fc4w : LOD_TENSOR.shape(2048, 6272).dtype(float32).stop_gradient(False),\n",
       "   var fc4w@GRAD : LOD_TENSOR.shape(2048, 6272).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param fc3w : LOD_TENSOR.shape(100, 2048).dtype(float32).stop_gradient(False),\n",
       "   var fc3w@GRAD : LOD_TENSOR.shape(100, 2048).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param deconv1b : LOD_TENSOR.shape(128,).dtype(float32).stop_gradient(False),\n",
       "   var deconv1b@GRAD : LOD_TENSOR.shape(128,).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param deconv1w : LOD_TENSOR.shape(128, 128, 5, 5).dtype(float32).stop_gradient(False),\n",
       "   var deconv1w@GRAD : LOD_TENSOR.shape(128, 128, 5, 5).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param deconv2b : LOD_TENSOR.shape(1,).dtype(float32).stop_gradient(False),\n",
       "   var deconv2b@GRAD : LOD_TENSOR.shape(1,).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param deconv2w : LOD_TENSOR.shape(128, 1, 5, 5).dtype(float32).stop_gradient(False),\n",
       "   var deconv2w@GRAD : LOD_TENSOR.shape(128, 1, 5, 5).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param bn32 : LOD_TENSOR.shape(2048,).dtype(float32).stop_gradient(False),\n",
       "   var bn32@GRAD : LOD_TENSOR.shape(2048,).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param bn31 : LOD_TENSOR.shape(2048,).dtype(float32).stop_gradient(False),\n",
       "   var bn31@GRAD : LOD_TENSOR.shape(2048,).dtype(float32).stop_gradient(False)),\n",
       "  (persist trainable param fc3b : LOD_TENSOR.shape(2048,).dtype(float32).stop_gradient(False),\n",
       "   var fc3b@GRAD : LOD_TENSOR.shape(2048,).dtype(float32).stop_gradient(False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = fluid.optimizer.Adam(learning_rate=LEARNING_RATE)\n",
    "opt.minimize(loss=d_loss)\n",
    "parameters = [p.name for p in g_program.global_block().all_parameters()]\n",
    "opt.minimize(loss=dg_loss, parameter_list=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675ee7ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:25.325579Z",
     "start_time": "2021-08-16T18:32:25.297938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khoa/miniconda3/envs/bd_lira/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: \u001b[93m\n",
      "Warning:\n",
      "API \"paddle.dataset.mnist.train\" is deprecated since 2.0.0, and will be removed in future versions. Please use \"paddle.vision.datasets.MNIST\" instead.\n",
      "reason: Please use new dataset API which supports paddle.io.DataLoader \u001b[0m\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128   # Minibatch size\n",
    "\n",
    "train_reader = fluid.io.batch(\n",
    "    fluid.io.shuffle(\n",
    "        paddle.dataset.mnist.train(), buf_size=60000),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8cabc00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:27.611652Z",
     "start_time": "2021-08-16T18:32:27.472276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 11:32:27.491343 3416898 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 10.2\n",
      "W0816 11:32:27.491688 3416898 dynamic_loader.cc:267] The third-party dynamic library (libcudnn.so) that Paddle depends on is not configured correctly. (error code is libcudnn.so: cannot open shared object file: No such file or directory)\n",
      "  Suggestions:\n",
      "  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\n",
      "  2. Configure third-party dynamic library environment variables as follows:\n",
      "  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\n",
      "  - Windows: set PATH by `set PATH=XXX;\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "(PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\n  [Hint: cudnn_dso_handle should not be null.] (at /paddle/paddle/fluid/platform/dynload/cudnn.cc:59)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3416898/665258528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPUPlace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_startup_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/bd_lira/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                 return_merged=return_merged)\n\u001b[1;32m   1109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     def _run_impl(self, program, feed, fetch_list, feed_var_name,\n",
      "\u001b[0;32m~/miniconda3/envs/bd_lira/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bd_lira/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                 \u001b[0muse_program_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_program_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0muse_prune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_prune\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m                 return_merged=return_merged)\n\u001b[0m\u001b[1;32m   1109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bd_lira/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_impl\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                 \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                 \u001b[0mreturn_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_numpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                 use_program_cache=use_program_cache)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bd_lira/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_program\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_program_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             self._default_executor.run(program.desc, scope, 0, True, True,\n\u001b[0;32m-> 1329\u001b[0;31m                                        [fetch_var_name])\n\u001b[0m\u001b[1;32m   1330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             self._default_executor.run_prepared_ctx(ctx, scope, False, False,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: (PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\n  [Hint: cudnn_dso_handle should not be null.] (at /paddle/paddle/fluid/platform/dynload/cudnn.cc:59)\n"
     ]
    }
   ],
   "source": [
    "print(f'Using {\"GPU\" if use_gpu else \"CPU\"}')\n",
    "if use_gpu:\n",
    "    exe = fluid.Executor(fluid.CUDAPlace(0))\n",
    "else:\n",
    "    exe = fluid.Executor(fluid.CPUPlace())\n",
    "\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc7e90b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T20:38:10.936443Z",
     "start_time": "2021-08-09T20:38:07.805377Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g_program' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_598114/214892391.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Fake image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         generated_image = exe.run(g_program,\n\u001b[0m\u001b[1;32m     36\u001b[0m                                   \u001b[0mfeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'noise'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoise_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                   fetch_list=[g_img])[0]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'g_program' is not defined"
     ]
    }
   ],
   "source": [
    "t_time = 0\n",
    "losses = [[], []]\n",
    "\n",
    "# The number of iterations of the discriminator\n",
    "NUM_TRAIN_TIMES_OF_DG = 2  \n",
    "\n",
    "# Noise data of final generated image\n",
    "const_n = np.random.uniform(\n",
    "    low=-1.0, high=1.0,\n",
    "    size=[batch_size, NOISE_SIZE]).astype('float32')\n",
    "\n",
    "for pass_id in range(epoch):\n",
    "    for batch_id, data in enumerate(train_reader()):\n",
    "        if len(data) != batch_size:\n",
    "            continue\n",
    "\n",
    "        # Generating noise data during training\n",
    "        noise_data = np.random.uniform(\n",
    "            low=-1.0, high=1.0,\n",
    "            size=[batch_size, NOISE_SIZE]).astype('float32')\n",
    "\n",
    "        # Real image\n",
    "        real_image = np.array(list(map(lambda x: x[0], data))).reshape(\n",
    "            -1, 784).astype('float32')\n",
    "        # Real label\n",
    "        real_labels = np.ones(\n",
    "            shape=[real_image.shape[0], 1], dtype='float32')\n",
    "        # Fake label\n",
    "        fake_labels = np.zeros(\n",
    "            shape=[real_image.shape[0], 1], dtype='float32')\n",
    "        total_label = np.concatenate([real_labels, fake_labels])\n",
    "        s_time = time.time()\n",
    "\n",
    "        # Fake image\n",
    "        generated_image = exe.run(g_program,\n",
    "                                  feed={'noise': noise_data},\n",
    "                                  fetch_list=[g_img])[0]\n",
    "\n",
    "        total_images = np.concatenate([real_image, generated_image])\n",
    "\n",
    "        # D loss of judging fake pictures as fake\n",
    "        d_loss_1 = exe.run(d_program,\n",
    "                           feed={\n",
    "                               'img': generated_image,\n",
    "                               'label': fake_labels,\n",
    "                           },\n",
    "                           fetch_list=[d_loss])[0][0]\n",
    "\n",
    "        # D loss of judging true pictures as true\n",
    "        d_loss_2 = exe.run(d_program,\n",
    "                           feed={\n",
    "                               'img': real_image,\n",
    "                               'label': real_labels,\n",
    "                           },\n",
    "                           fetch_list=[d_loss])[0][0]\n",
    "\n",
    "        d_loss_n = d_loss_1 + d_loss_2\n",
    "        losses[0].append(d_loss_n)\n",
    "\n",
    "        # Training generator\n",
    "        for _ in six.moves.xrange(NUM_TRAIN_TIMES_OF_DG):\n",
    "            noise_data = np.random.uniform(\n",
    "                low=-1.0, high=1.0,\n",
    "                size=[batch_size, NOISE_SIZE]).astype('float32')\n",
    "            dg_loss_n = exe.run(dg_program,\n",
    "                                 feed={'noise': noise_data},\n",
    "                                 fetch_list=[dg_loss])[0][0]\n",
    "            losses[1].append(dg_loss_n)\n",
    "        t_time += (time.time() - s_time)\n",
    "        if batch_id % 10 == 0 :\n",
    "            if not os.path.exists(output):\n",
    "                os.makedirs(output)\n",
    "            # Results of each round\n",
    "            generated_images = exe.run(g_program_test,\n",
    "                                       feed={'noise': const_n},\n",
    "                                       fetch_list=[g_img])[0]\n",
    "            # Connect real pictures to generated pictures\n",
    "            total_images = np.concatenate([real_image, generated_images])\n",
    "            fig = plot(total_images)\n",
    "            msg = \"Epoch ID={0} Batch ID={1} D-Loss={2} DG-Loss={3}\\n \".format(\n",
    "                pass_id, batch_id,\n",
    "                d_loss_n, dg_loss_n)\n",
    "            print(msg)\n",
    "            plt.title(msg)\n",
    "            plt.savefig(\n",
    "                '{}/{:04d}_{:04d}.png'.format(output, pass_id,\n",
    "                                              batch_id),\n",
    "                bbox_inches='tight')\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0508ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no,batch_id):\n",
    "  return PIL.Image.open('output_dcgan/{:04d}_{:04d}.png'.format(epoch_no,batch_id))\n",
    "\n",
    "# Observe the generated images of the 10th epoch and 460 batches:\n",
    "display_image(10,460)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
